{"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"language_info":{"name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3}},"notebookId":"7be5f276-9ef6-4d3a-8770-ffe4c935a3ab"},"cells":[{"cell_type":"markdown","source":"## Важно:\n\nПожалуйста, поддерживайте ваш код в хорошем состоянии, пишите комментарии, убирайте бесполезные ячейки, пишите модели в специально отведенных модулях. Проверяющие могут **НА СВОЕ УСМОТРЕНИЕ** снижать баллы за:\n\n1. Говнокод\n2. Неэффективные решения\n3. Вермишель из ячеек в тетрадке\n4. Все остальное что им не понравилось\n","metadata":{"cellId":"lufwgaurkt5xikybl0wuv"}},{"cell_type":"code","source":"#!XL\nimport wandb","metadata":{"execution_id":"51723590-855f-45b4-ab89-45586c691103","cellId":"4ec0h6ig9dspfvaqjwbxd","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Важно 2 (0 - 0.15 балла):\n\nЗа использование логгеров типа wandb/comet/neptune и красивую сборку этой домашки в виде графиков/картинок в этих логгерах мы будем выдавать бонусные баллы.\n\n","metadata":{"cellId":"0fb4isviqbm9dqrdq215bkt"}},{"cell_type":"markdown","source":"## Важно 3:\n\nРешением домашки является архив с использованными тетрадками/модулями, а так же **.pdf файл** с отчетом по проделанной работе по каждому пункту задачи. \nВ нем необходимо описать какие эксперименты вы производили чтобы получить результат который вы получили, а так же обосновать почему вы решили использовать штуки которые вы использовали (например дополнительные лоссы для стабилизации, WGAN-GP, а не GAN/WGAN+clip)\n","metadata":{"cellId":"wpq35tavdy9563ji2tuwna"}},{"cell_type":"code","source":"#!XL\nimport numpy as np\nimport torchvision\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\n\nfrom tqdm.notebook import tqdm\nfrom IPython.display import clear_output\n\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"cellId":"gr0wymskr47qw38u4226lm","trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"#!XL\nimport requests\n\ndef download_file_from_google_drive(id, destination):\n    def get_confirm_token(response):\n        for key, value in response.cookies.items():\n            if key.startswith('download_warning'):\n                return value\n\n        return None\n\n    def save_response_content(response, destination):\n        CHUNK_SIZE = 32768\n\n        with open(destination, \"wb\") as f:\n            for chunk in response.iter_content(CHUNK_SIZE):\n                if chunk: # filter out keep-alive new chunks\n                    f.write(chunk)\n\n    URL = \"https://docs.google.com/uc?export=download\"\n\n    session = requests.Session()\n\n    response = session.get(URL, params = { 'id' : id }, stream = True)\n    token = get_confirm_token(response)\n\n    if token:\n        params = { 'id' : id, 'confirm' : token }\n        response = session.get(URL, params = params, stream = True)\n\n    save_response_content(response, destination)    \n\n\ndownload_file_from_google_drive('1F96x4LDbsTZGMMq81fZr7aduJCe8N95O', 'celeba.zip')","metadata":{"cellId":"u5keqxbh78nr4wwlg0yf","trusted":true},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)","\u001B[0;32m<ipython-input-3-3e172b8469a4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 33\u001B[0;31m \u001B[0mdownload_file_from_google_drive\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'1F96x4LDbsTZGMMq81fZr7aduJCe8N95O'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'celeba.zip'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     34\u001B[0m \u001B[0;31m#\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m<ipython-input-3-3e172b8469a4>\u001B[0m in \u001B[0;36mdownload_file_from_google_drive\u001B[0;34m(id, destination)\u001B[0m\n\u001B[1;32m     28\u001B[0m         \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mURL\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparams\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstream\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 30\u001B[0;31m     \u001B[0msave_response_content\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdestination\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     31\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m<ipython-input-3-3e172b8469a4>\u001B[0m in \u001B[0;36msave_response_content\u001B[0;34m(response, destination)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdestination\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"wb\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0mchunk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miter_content\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mCHUNK_SIZE\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mchunk\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;31m# filter out keep-alive new chunks\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m                     \u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchunk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/kernel/lib/python3.7/site-packages/requests/models.py\u001B[0m in \u001B[0;36mgenerate\u001B[0;34m()\u001B[0m\n\u001B[1;32m    751\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraw\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'stream'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    752\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 753\u001B[0;31m                     \u001B[0;32mfor\u001B[0m \u001B[0mchunk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraw\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstream\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchunk_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecode_content\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    754\u001B[0m                         \u001B[0;32myield\u001B[0m \u001B[0mchunk\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    755\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mProtocolError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/kernel/lib/python3.7/site-packages/urllib3/response.py\u001B[0m in \u001B[0;36mstream\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m    570\u001B[0m         \"\"\"\n\u001B[1;32m    571\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchunked\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msupports_chunked_reads\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 572\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0mline\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_chunked\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mamt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecode_content\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdecode_content\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    573\u001B[0m                 \u001B[0;32myield\u001B[0m \u001B[0mline\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    574\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/kernel/lib/python3.7/site-packages/urllib3/response.py\u001B[0m in \u001B[0;36mread_chunked\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m    765\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchunk_left\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    766\u001B[0m                     \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 767\u001B[0;31m                 \u001B[0mchunk\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_handle_chunk\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mamt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    768\u001B[0m                 decoded = self._decode(\n\u001B[1;32m    769\u001B[0m                     \u001B[0mchunk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecode_content\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdecode_content\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mflush_decoder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/kernel/lib/python3.7/site-packages/urllib3/response.py\u001B[0m in \u001B[0;36m_handle_chunk\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    709\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchunk_left\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    710\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mamt\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchunk_left\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 711\u001B[0;31m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_safe_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mamt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    712\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchunk_left\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchunk_left\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mamt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    713\u001B[0m             \u001B[0mreturned_chunk\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/python3.7/http/client.py\u001B[0m in \u001B[0;36m_safe_read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    622\u001B[0m         \u001B[0ms\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    623\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0mamt\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 624\u001B[0;31m             \u001B[0mchunk\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mamt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mMAXAMOUNT\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    625\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mchunk\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    626\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mIncompleteRead\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mb''\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mamt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/python3.7/socket.py\u001B[0m in \u001B[0;36mreadinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    587\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    588\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 589\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv_into\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    590\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    591\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_timeout_occurred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/python3.7/ssl.py\u001B[0m in \u001B[0;36mrecv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1069\u001B[0m                   \u001B[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001B[0m \u001B[0;34m%\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1070\u001B[0m                   self.__class__)\n\u001B[0;32m-> 1071\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnbytes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbuffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1072\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1073\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv_into\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbuffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnbytes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/python3.7/ssl.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m    927\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    928\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mbuffer\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 929\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sslobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbuffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    930\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    931\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sslobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;31mKeyboardInterrupt\u001B[0m: "]}],"execution_count":3},{"cell_type":"code","source":"#!XL\n%enable_full_walk","metadata":{"cellId":"kh1tkdfyde40ds3ku4f7g","trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#!XL\nimport zipfile\nwith zipfile.ZipFile('celeba.zip', 'r') as zip_ref:\n    zip_ref.extractall('.')","metadata":{"cellId":"1m1o3awxea7iqkxumulns","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"В этом домашнем задании мы будем работать с Celeba. Celeba - это уже известный вам датасет состоящий из фотографий селеб в их привычной местности:","metadata":{"cellId":"rnwzhzuwrolrjcp4d6z8br"}},{"cell_type":"code","source":"#!XL\nimage_size=(128, 128)\ntransforms = torchvision.transforms.Compose([\n    torchvision.transforms.Resize(image_size),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n])","metadata":{"cellId":"ts903ombkolatbue4t7r89","trusted":true},"outputs":[],"execution_count":34},{"cell_type":"code","source":"#!XL\nceleba = torchvision.datasets.CelebA('celeba', target_type='attr', transform=transforms, download=False)\nceleba_dataloader = torch.utils.data.DataLoader(celeba, 64, shuffle=True, num_workers=32)","metadata":{"cellId":"6307bmruh8id7k984ll5ue","trusted":true},"outputs":[],"execution_count":35},{"cell_type":"code","source":"#!XL\nindex2attr = {i:j for i, j in enumerate(celeba.attr_names)}","metadata":{"cellId":"7jzfc4xl7itwyv1lrh2fde","trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#!XL\nfrom importlib import reload","metadata":{"cellId":"t358uelc8ca3cpqo94vayc","trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"#!XL\nfrom pytorch_lightning import Trainer\nfrom pytorch_lightning.loggers import WandbLogger\nimport model as model_","metadata":{"cellId":"c3k2apr7z8ou8e8wprdyc","trusted":true},"outputs":[],"execution_count":30},{"cell_type":"code","source":"#!XL\nreload(model_)","metadata":{"cellId":"5oo7kfjugz34d5gjko98v2","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<module 'model' from '/home/jupyter/work/resources/DeepGenerativeModels/homework/2-GAN/model.py'>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"#!XL\nx, y = next(iter(celeba_dataloader))","metadata":{"cellId":"z9xiklj9huqrjiz14gvp6o","trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"#!XL\ntrainer = Trainer(logger=WandbLogger(project='GAN-homework_2-GAN', save_dir=None), log_every_n_steps=1, gpus=-1, accelerator='dp')\nmodel__ = model_.VanillaStarGAN(x, y, index2attr)","metadata":{"execution_id":"4d4e3042-823b-45dd-b73e-5e649b8e2fd0","cellId":"xkrg0ej3fqrq4y9g9aipkm","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!XL\n__spec__ = None\ntrainer.fit(model__, celeba_dataloader, celeba_dataloader)","metadata":{"execution_id":"612ec9ec-27a7-47a4-89e6-da165f586e3d","cellId":"gx03l1jpfw4fzqs8mdenej","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!XL\n%%debug","metadata":{"cellId":"7p14qn94wioxoagl2kkjua","trusted":true},"outputs":[{"output_type":"stream","name":"stdin","text":"ipdb>  locals()\n"},{"output_type":"stream","name":"stdout","text":"NOTE: Enter 'c' at the ipdb>  prompt to continue execution.\n> \u001B[0;32m<string>\u001B[0m(1)\u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\n{'nn': <module 'torch.nn' from '/usr/local/lib/python3.7/dist-packages/torch/nn/__init__.py'>, '_oh': {9: <module 'model' from '/home/jupyter/work/resources/DeepGenerativeModels/homework/2-GAN/model.py'>}, '_i8': '\\nfrom pytorch_lightning import Trainer\\nfrom pytorch_lightning.loggers import WandbLogger\\nimport model as model_\\n#', '_9': <module 'model' from '/home/jupyter/work/resources/DeepGenerativeModels/homework/2-GAN/model.py'>, '___': '', '_i1': '\\nimport wandb\\n#', '_ih': ['', 'import wandb\\n#', \"import numpy as np\\nimport torchvision\\n\\nimport torch\\nfrom torch import nn\\nfrom torch.nn import functional as F\\n\\nfrom tqdm.notebook import tqdm\\nfrom IPython.display import clear_output\\n\\n\\nimport matplotlib.pyplot as plt\\nget_ipython().run_line_magic('matplotlib', 'inline')\\n#\", \"get_ipython().run_line_magic('enable_full_walk', '')\\n#\", 'image_size=(128, 128)\\ntransforms = torchvision.transforms.Compose([\\n    torchvision.transforms.Resize(image_size),\\n    torchvision.transforms.ToTensor(),\\n    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\\n])\\n#', \"celeba = torchvision.datasets.CelebA('celeba', target_type='attr', transform=transforms, download=False)\\nceleba_dataloader = torch.utils.data.DataLoader(celeba, 3, shuffle=True)\\n#\", 'index2attr = {i:j for i, j in enumerate(celeba.attr_names)}\\n#', 'from importlib import reload\\n#', 'from pytorch_lightning import Trainer\\nfrom pytorch_lightning.loggers import WandbLogger\\nimport model as model_\\n#', 'reload(model_)\\n#', 'x, y = next(iter(celeba_dataloader))\\n#', \"trainer = Trainer(logger=WandbLogger(project='GAN-homework_2-GAN', save_dir=None), log_every_n_steps=1, gpus=-1, accelerator='dp')\\nmodel__ = model_.VanillaStarGAN(x, y, index2attr)\\n#\", '__spec__ = None\\ntrainer.fit(model__, celeba_dataloader, celeba_dataloader)\\n#', \"get_ipython().run_line_magic('debug', '')\\n#\", \"get_ipython().run_cell_magic('debug', '', '#\\\\n')\"], 'image_size': (128, 128), '_': <module 'model' from '/home/jupyter/work/resources/DeepGenerativeModels/homework/2-GAN/model.py'>, '_dh': ['/home/jupyter/work/resources/DeepGenerativeModels/homework/2-GAN'], '__': '', '_i13': '\\n%debug\\n#', 'celeba': Dataset CelebA\n    Number of datapoints: 162770\n    Root location: celeba\n    Target type: ['attr']\n    Split: train\n    StandardTransform\nTransform: Compose(\n               Resize(size=(128, 128), interpolation=PIL.Image.BILINEAR)\n               ToTensor()\n               Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n           ), 'execute_script': <bound method ScriptExecutor.execute of <ml_kernel.script_executor.ScriptExecutor object at 0x7fd0f899ba50>>, 'x': tensor([[[[ 0.7412,  0.7490,  0.7569,  ...,  0.8353,  0.8353,  0.8353],\n          [ 0.7412,  0.7490,  0.7569,  ...,  0.8353,  0.8353,  0.8353],\n          [ 0.7412,  0.7490,  0.7569,  ...,  0.8353,  0.8353,  0.8353],\n          ...,\n          [-0.7176, -0.7098, -0.7098,  ...,  0.2549,  0.3255,  0.2863],\n          [-0.7804, -0.7647, -0.7569,  ..., -0.4275,  0.0667,  0.2706],\n          [-0.8824, -0.8667, -0.8588,  ..., -0.7804, -0.6863, -0.4980]],\n\n         [[ 0.6078,  0.6157,  0.6235,  ...,  0.7333,  0.7333,  0.7333],\n          [ 0.6078,  0.6157,  0.6235,  ...,  0.7333,  0.7333,  0.7333],\n          [ 0.6078,  0.6157,  0.6235,  ...,  0.7333,  0.7333,  0.7333],\n          ...,\n          [-0.7020, -0.6941, -0.6941,  ...,  0.2235,  0.2863,  0.2314],\n          [-0.7647, -0.7490, -0.7412,  ..., -0.4510,  0.0275,  0.2235],\n          [-0.8667, -0.8510, -0.8431,  ..., -0.7961, -0.7098, -0.5373]],\n\n         [[ 0.2627,  0.2706,  0.2784,  ...,  0.4824,  0.4824,  0.4824],\n          [ 0.2627,  0.2706,  0.2784,  ...,  0.4824,  0.4824,  0.4824],\n          [ 0.2627,  0.2706,  0.2784,  ...,  0.4824,  0.4824,  0.4824],\n          ...,\n          [-0.7412, -0.7333, -0.7333,  ...,  0.1216,  0.1529,  0.0824],\n          [-0.8039, -0.7882, -0.7804,  ..., -0.5529, -0.1059,  0.0667],\n          [-0.9059, -0.8902, -0.8824,  ..., -0.8980, -0.8510, -0.6941]]],\n\n\n        [[[ 0.2392,  0.2471,  0.2471,  ...,  0.4902,  0.4980,  0.5059],\n          [ 0.2549,  0.2627,  0.2706,  ...,  0.4902,  0.4980,  0.5059],\n          [ 0.2706,  0.2784,  0.2863,  ...,  0.4902,  0.4980,  0.5059],\n          ...,\n          [ 0.6941,  0.6941,  0.6863,  ..., -0.9843, -0.9529, -0.9294],\n          [ 0.6941,  0.6941,  0.6863,  ..., -0.9922, -0.9686, -0.9216],\n          [ 0.6784,  0.6863,  0.6941,  ..., -0.9765, -0.9686, -0.9216]],\n\n         [[ 0.1608,  0.1686,  0.1686,  ...,  0.3961,  0.4039,  0.4118],\n          [ 0.1765,  0.1843,  0.1922,  ...,  0.3961,  0.4039,  0.4118],\n          [ 0.1922,  0.2000,  0.2078,  ...,  0.3961,  0.4039,  0.4118],\n          ...,\n          [ 0.6549,  0.6549,  0.6471,  ..., -0.9765, -0.9608, -0.9608],\n          [ 0.6549,  0.6549,  0.6471,  ..., -0.9843, -0.9765, -0.9529],\n          [ 0.6392,  0.6471,  0.6549,  ..., -0.9686, -0.9765, -0.9451]],\n\n         [[ 0.0667,  0.0745,  0.0745,  ...,  0.2706,  0.2784,  0.2863],\n          [ 0.0824,  0.0902,  0.0980,  ...,  0.2706,  0.2784,  0.2863],\n          [ 0.0980,  0.1059,  0.1137,  ...,  0.2706,  0.2784,  0.2863],\n          ...,\n          [ 0.6078,  0.6078,  0.6000,  ..., -1.0000, -0.9922, -0.9765],\n          [ 0.6078,  0.6078,  0.6000,  ..., -1.0000, -0.9922, -0.9765],\n          [ 0.5922,  0.6000,  0.6078,  ..., -1.0000, -1.0000, -0.9843]]],\n\n\n        [[[ 0.1216,  0.1137,  0.1059,  ..., -0.8353, -0.8353, -0.8353],\n          [ 0.1294,  0.1216,  0.1137,  ..., -0.8353, -0.8353, -0.8353],\n          [ 0.1294,  0.1216,  0.1137,  ..., -0.8353, -0.8353, -0.8275],\n          ...,\n          [-0.3255, -0.1529, -0.0902,  ..., -0.5216, -0.4039, -0.5137],\n          [-0.3569, -0.1608, -0.0588,  ..., -0.5294, -0.4118, -0.4980],\n          [-0.3804, -0.1529, -0.0510,  ..., -0.5765, -0.4275, -0.4902]],\n\n         [[ 0.0431,  0.0353,  0.0275,  ..., -0.8196, -0.8196, -0.8196],\n          [ 0.0510,  0.0431,  0.0353,  ..., -0.8196, -0.8196, -0.8275],\n          [ 0.0510,  0.0431,  0.0353,  ..., -0.8275, -0.8275, -0.8353],\n          ...,\n          [-0.4824, -0.3020, -0.2314,  ..., -0.5765, -0.4667, -0.5843],\n          [-0.5059, -0.3098, -0.2000,  ..., -0.5922, -0.4824, -0.5686],\n          [-0.5294, -0.2941, -0.1922,  ..., -0.6392, -0.4902, -0.5608]],\n\n         [[ 0.4353,  0.4275,  0.4196,  ..., -0.4353, -0.4667, -0.4980],\n          [ 0.4431,  0.4353,  0.4353,  ..., -0.4431, -0.4745, -0.5059],\n          [ 0.4588,  0.4510,  0.4431,  ..., -0.4588, -0.4902, -0.5216],\n          ...,\n          [-0.5765, -0.4353, -0.4196,  ..., -0.6235, -0.4980, -0.6235],\n          [-0.6000, -0.4431, -0.3882,  ..., -0.6314, -0.5059, -0.6078],\n          [-0.6235, -0.4353, -0.3804,  ..., -0.6784, -0.5216, -0.6000]]]]), 'torchvision': <module 'torchvision' from '/usr/local/lib/python3.7/dist-packages/torchvision/__init__.py'>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x7fd1000e35d0>, 'Trainer': <class 'pytorch_lightning.trainer.trainer.Trainer'>, '_i12': '\\n__spec__ = None\\ntrainer.fit(model__, celeba_dataloader, celeba_dataloader)\\n#', '__ENABLE_FULL_WALK_VARIABLES__': True, '_i9': '\\nreload(model_)\\n#', '_i6': '\\nindex2attr = {i:j for i, j in enumerate(celeba.attr_names)}\\n#', '_i10': '\\nx, y = next(iter(celeba_dataloader))\\n#', 'Out': {9: <module 'model' from '/home/jupyter/work/resources/DeepGenerativeModels/homework/2-GAN/model.py'>}, 'y': tensor([[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n         1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n         1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1],\n        [0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n         1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]]), '__spec__': None, '_i3': '\\n%enable_full_walk\\n#', 'clear_output': <function clear_output at 0x7fd108728320>, 'trainer': <pytorch_lightning.trainer.trainer.Trainer object at 0x7fd0371b2510>, 'torch': <module 'torch' from '/usr/local/lib/python3.7/dist-packages/torch/__init__.py'>, '_i5': \"\\nceleba = torchvision.datasets.CelebA('celeba', target_type='attr', transform=transforms, download=False)\\nceleba_dataloader = torch.utils.data.DataLoader(celeba, 3, shuffle=True)\\n#\", '__builtin__': <module 'builtins' (built-in)>, 'index2attr': {0: '5_o_Clock_Shadow', 1: 'Arched_Eyebrows', 2: 'Attractive', 3: 'Bags_Under_Eyes', 4: 'Bald', 5: 'Bangs', 6: 'Big_Lips', 7: 'Big_Nose', 8: 'Black_Hair', 9: 'Blond_Hair', 10: 'Blurry', 11: 'Brown_Hair', 12: 'Bushy_Eyebrows', 13: 'Chubby', 14: 'Double_Chin', 15: 'Eyeglasses', 16: 'Goatee', 17: 'Gray_Hair', 18: 'Heavy_Makeup', 19: 'High_Cheekbones', 20: 'Male', 21: 'Mouth_Slightly_Open', 22: 'Mustache', 23: 'Narrow_Eyes', 24: 'No_Beard', 25: 'Oval_Face', 26: 'Pale_Skin', 27: 'Pointy_Nose', 28: 'Receding_Hairline', 29: 'Rosy_Cheeks', 30: 'Sideburns', 31: 'Smiling', 32: 'Straight_Hair', 33: 'Wavy_Hair', 34: 'Wearing_Earrings', 35: 'Wearing_Hat', 36: 'Wearing_Lipstick', 37: 'Wearing_Necklace', 38: 'Wearing_Necktie', 39: 'Young'}, 'celeba_dataloader': <torch.utils.data.dataloader.DataLoader object at 0x7fd0dc9ff950>, '_i11': \"\\ntrainer = Trainer(logger=WandbLogger(project='GAN-homework_2-GAN', save_dir=None), log_every_n_steps=1, gpus=-1, accelerator='dp')\\nmodel__ = model_.VanillaStarGAN(x, y, index2attr)\\n#\", '_i7': '\\nfrom importlib import reload\\n#', 'F': <module 'torch.nn.functional' from '/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py'>, 'model_': <module 'model' from '/home/jupyter/work/resources/DeepGenerativeModels/homework/2-GAN/model.py'>, '_i2': '\\nimport numpy as np\\nimport torchvision\\n\\nimport torch\\nfrom torch import nn\\nfrom torch.nn import functional as F\\n\\nfrom tqdm.notebook import tqdm\\nfrom IPython.display import clear_output\\n\\n\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n#', 'plt': <module 'matplotlib.pyplot' from '/kernel/lib/python3.7/site-packages/matplotlib/pyplot.py'>, 'In': ['', 'import wandb\\n#', \"import numpy as np\\nimport torchvision\\n\\nimport torch\\nfrom torch import nn\\nfrom torch.nn import functional as F\\n\\nfrom tqdm.notebook import tqdm\\nfrom IPython.display import clear_output\\n\\n\\nimport matplotlib.pyplot as plt\\nget_ipython().run_line_magic('matplotlib', 'inline')\\n#\", \"get_ipython().run_line_magic('enable_full_walk', '')\\n#\", 'image_size=(128, 128)\\ntransforms = torchvision.transforms.Compose([\\n    torchvision.transforms.Resize(image_size),\\n    torchvision.transforms.ToTensor(),\\n    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\\n])\\n#', \"celeba = torchvision.datasets.CelebA('celeba', target_type='attr', transform=transforms, download=False)\\nceleba_dataloader = torch.utils.data.DataLoader(celeba, 3, shuffle=True)\\n#\", 'index2attr = {i:j for i, j in enumerate(celeba.attr_names)}\\n#', 'from importlib import reload\\n#', 'from pytorch_lightning import Trainer\\nfrom pytorch_lightning.loggers import WandbLogger\\nimport model as model_\\n#', 'reload(model_)\\n#', 'x, y = next(iter(celeba_dataloader))\\n#', \"trainer = Trainer(logger=WandbLogger(project='GAN-homework_2-GAN', save_dir=None), log_every_n_steps=1, gpus=-1, accelerator='dp')\\nmodel__ = model_.VanillaStarGAN(x, y, index2attr)\\n#\", '__spec__ = None\\ntrainer.fit(model__, celeba_dataloader, celeba_dataloader)\\n#', \"get_ipython().run_line_magic('debug', '')\\n#\", \"get_ipython().run_cell_magic('debug', '', '#\\\\n')\"], 'transforms': Compose(\n    Resize(size=(128, 128), interpolation=PIL.Image.BILINEAR)\n    ToTensor()\n    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n), 'model__': VanillaStarGAN(\n  (discriminator): Discriminator(\n    (main): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n      (1): LeakyReLU(negative_slope=0.01)\n      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n      (3): LeakyReLU(negative_slope=0.01)\n      (4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n      (5): LeakyReLU(negative_slope=0.01)\n      (6): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n      (7): LeakyReLU(negative_slope=0.01)\n      (8): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n      (9): LeakyReLU(negative_slope=0.01)\n      (10): Conv2d(1024, 2048, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n      (11): LeakyReLU(negative_slope=0.01)\n    )\n    (conv1): Conv2d(2048, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (conv2): Conv2d(2048, 40, kernel_size=(2, 2), stride=(1, 1), bias=False)\n  )\n  (generator): Generator(\n    (main): Sequential(\n      (0): Conv2d(43, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n      (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n      (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n      (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n      (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (8): ReLU(inplace=True)\n      (9): ResidualBlock(\n        (main): Sequential(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (10): ResidualBlock(\n        (main): Sequential(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (11): ResidualBlock(\n        (main): Sequential(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (12): ResidualBlock(\n        (main): Sequential(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (13): ResidualBlock(\n        (main): Sequential(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (14): ResidualBlock(\n        (main): Sequential(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (15): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n      (16): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (17): ReLU(inplace=True)\n      (18): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n      (19): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (20): ReLU(inplace=True)\n      (21): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n      (22): Tanh()\n    )\n  )\n), 'execute_livy_statement': <bound method LivyExecutor.execute_livy_statement of <ml_kernel.magics.livy_executor.LivyExecutor object at 0x7fd0f899bd50>>, 'EphemeralVariable.ML_KERNEL_CWD': '/home/jupyter/work/resources/DeepGenerativeModels/homework/2-GAN', 'reload': <function reload at 0x7fd10e582f80>, 'tqdm': <class 'tqdm.notebook.tqdm_notebook'>, 'WandbLogger': <class 'pytorch_lightning.loggers.wandb.WandbLogger'>, 'wandb': <module 'wandb' from '/home/jupyter/.local/lib/python3.7/site-packages/wandb/__init__.py'>, '__name__': '__main__', 'np': <module 'numpy' from '/kernel/lib/python3.7/site-packages/numpy/__init__.py'>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x7fd1000e35d0>, '_i4': '\\nimage_size=(128, 128)\\ntransforms = torchvision.transforms.Compose([\\n    torchvision.transforms.Resize(image_size),\\n    torchvision.transforms.ToTensor(),\\n    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\\n])\\n#', '_i': '\\n%debug\\n#', '_ii': '\\n__spec__ = None\\ntrainer.fit(model__, celeba_dataloader, celeba_dataloader)\\n#', '_iii': \"\\ntrainer = Trainer(logger=WandbLogger(project='GAN-homework_2-GAN', save_dir=None), log_every_n_steps=1, gpus=-1, accelerator='dp')\\nmodel__ = model_.VanillaStarGAN(x, y, index2attr)\\n#\", '_i14': '\\n%%debug\\n#', '__builtins__': <module 'builtins' (built-in)>, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7fd1000b3f90>>}\n"},{"output_type":"stream","name":"stdin","text":"ipdb>  exit\n"}],"execution_count":14},{"cell_type":"markdown","source":"В этой домашней работе вам предлагается повторить результаты статьи StarGAN (https://arxiv.org/abs/1711.09020). \n\nОсновная часть домашнего задания - чтение статьи и улучшение результатов, поэтому обязательно прочитайте не только StarGAN, но и другие Image-to-Image GAN подходы того времени (17-18 год) \n","metadata":{"cellId":"5lsn6jvhlfme4ivmjgctmv"}},{"cell_type":"markdown","source":"## Задача 1 (0.4 балла):\n\nПовторить результаты StarGAN используя только CelebA\n\nчто это значит: в статье предлагается способ использовать несколько датасетов и выучивание аттрибутов уникальных для какого-то одного датасета. Мы не просим вас это делать, вам достаточно просто обучить StarGAN на CelebA","metadata":{"cellId":"6b8f3tu6rp9n9fz3pdds"}},{"cell_type":"code","source":"#!L\nmodel","metadata":{"cellId":"vq5yvlerdbjjxj8tkc8fi","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<ml_kernel.state.state.LazyVariable at 0x7fcf7c08b250>"},"metadata":{}}],"execution_count":82},{"cell_type":"code","source":"from model import StarGAN\nfrom utils import permute_labels\n\nmodel = StarGAN()","metadata":{"cellId":"dnuj95b3ts7ys0zta1zkba"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.train()\nfor image, label in tqdm(celeba_dataloader, leave=False, desc=f\"trainloop: {epoch}\"):\n    # YOUR CODE\n\nmodel.eval()\nfor ind, (image, label) in enumerate(celeba_val_dataloader): # batch = 1\n    if ind >= 10: break\n\n    # пример сравнения качества на глаз:\n    new_label = permute_labels(label)\n    plt.figure(figsize=(20, 10))\n    plt.subplot(1, 2, 1)\n    plt.imshow((image[0].permute(1, 2, 0) + 1) / 2)\n    plt.subplot(1, 2, 2)\n    fake_image = model.generate(image.to(device), new_label.to(device)).detach().cpu()[0]\n    plt.imshow((fake_image.permute(1, 2, 0) + 1) / 2)\n    plt.show()\n","metadata":{"cellId":"m7z2mc2sqe87tgrwpnpqs"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Важно 4: \n\nЕсли вы учите на колабе или на наших машинках, вероятнее всего что обучение будет очень долгим на картинках 256х256. Никто не мешает уменьшить разрешение, главное чтобы было видно что трансформации выучились\n\nЕще, кажется что не все аттрибуты селебы являются очень важными или достаточно представленными в датасете. Не запрещается убирать бесполезные аттрибуты (только обоснуйте почему так сделали в отчете)\n\nНе забывайте про аугментации\n\n## Важно 5: \n\nДа, мы знаем что в на гитхабе лежить готовый код на путорче для этой статьи. Проблема в том что он написал на torch 0.4, поэтому, если мы увидим что вы используете __старый__ код со старыми модулями, то мы:\n\n1. Будем неодобрительно смотреть\n2. За наглое списывание будем снимать баллы\n","metadata":{"cellId":"qge7o31vyaj3na9i6rqkmy"}},{"cell_type":"markdown","source":"## Задача 2 (0.2 балла): \n\nМерить качество на глаз - плохая идея. Подключите подсчет FID для каждой N эпохи, чтобы вы могли следить за прогрессом модели.\n\nСранение моделей между собой тоже возможно только по FID, поэтому трекайте его когда будете делать другие эксперименты","metadata":{"cellId":"0fvt5znbuezax5n30l3x009"}},{"cell_type":"markdown","source":"## Задача 3 (0.4 балла):\n\nЕсли вы будете дословно повторять архитектуру авторов статьи, вы сразу же увидите что обучение станет дико долгим и не очень стабильным. Возможно у вас получится предложить несколько улучшений, которые приведут к хорошему FID, к визуально лучшим результатам или к более стабильному обучению.\n\nВ этой задаче хочется чтобы вы попробовали улучшить результаты статьи используя либо то что уже знаете, либо что-то из релевантных статей по Im2Im современности","metadata":{"cellId":"nklvmt721tpsrzfx6717pi"}},{"cell_type":"markdown","source":"## Важно 6: \n\nКогда вы будете показывать визуальные трансформации которые делает ваш StarGAN, хорошей идеей будет сразу же зафиксировать набор картинок (очевидно из валидации) и набор трансформаций на которых вы будете показывать результаты. Например: 10 картинок разных людей на которых вы покажете Male-Female, Beard-noBeard, Old-Young трансформации","metadata":{"cellId":"4zitx661e5qb9h1tl9k3b4"}},{"cell_type":"markdown","source":"## Важно 7 (0.15 балла): \n\nВыдам дополнительные баллы если у вас получится визуально красивая перекраска волос в разные цвета","metadata":{"cellId":"ncz2ahkji0jwvahurjvw6"}}]}