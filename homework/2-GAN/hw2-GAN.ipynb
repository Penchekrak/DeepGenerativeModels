{"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"language_info":{"name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3}},"notebookId":"7be5f276-9ef6-4d3a-8770-ffe4c935a3ab"},"cells":[{"cell_type":"markdown","source":"## Важно:\n\nПожалуйста, поддерживайте ваш код в хорошем состоянии, пишите комментарии, убирайте бесполезные ячейки, пишите модели в специально отведенных модулях. Проверяющие могут **НА СВОЕ УСМОТРЕНИЕ** снижать баллы за:\n\n1. Говнокод\n2. Неэффективные решения\n3. Вермишель из ячеек в тетрадке\n4. Все остальное что им не понравилось\n","metadata":{"cellId":"lufwgaurkt5xikybl0wuv"}},{"cell_type":"markdown","source":"## Важно 2 (0 - 0.15 балла):\n\nЗа использование логгеров типа wandb/comet/neptune и красивую сборку этой домашки в виде графиков/картинок в этих логгерах мы будем выдавать бонусные баллы.\n\n","metadata":{"cellId":"0fb4isviqbm9dqrdq215bkt"}},{"cell_type":"markdown","source":"## Важно 3:\n\nРешением домашки является архив с использованными тетрадками/модулями, а так же **.pdf файл** с отчетом по проделанной работе по каждому пункту задачи. \nВ нем необходимо описать какие эксперименты вы производили чтобы получить результат который вы получили, а так же обосновать почему вы решили использовать штуки которые вы использовали (например дополнительные лоссы для стабилизации, WGAN-GP, а не GAN/WGAN+clip)\n","metadata":{"cellId":"wpq35tavdy9563ji2tuwna"}},{"cell_type":"code","source":"import numpy as np\nimport torchvision\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\n\nfrom tqdm.notebook import tqdm\nfrom IPython.display import clear_output\n\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"cellId":"gr0wymskr47qw38u4226lm","trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# import requests\n\n# def download_file_from_google_drive(id, destination):\n#     def get_confirm_token(response):\n#         for key, value in response.cookies.items():\n#             if key.startswith('download_warning'):\n#                 return value\n\n#         return None\n\n#     def save_response_content(response, destination):\n#         CHUNK_SIZE = 32768\n\n#         with open(destination, \"wb\") as f:\n#             for chunk in response.iter_content(CHUNK_SIZE):\n#                 if chunk: # filter out keep-alive new chunks\n#                     f.write(chunk)\n\n#     URL = \"https://docs.google.com/uc?export=download\"\n\n#     session = requests.Session()\n\n#     response = session.get(URL, params = { 'id' : id }, stream = True)\n#     token = get_confirm_token(response)\n\n#     if token:\n#         params = { 'id' : id, 'confirm' : token }\n#         response = session.get(URL, params = params, stream = True)\n\n#     save_response_content(response, destination)    \n\n\n# download_file_from_google_drive('1F96x4LDbsTZGMMq81fZr7aduJCe8N95O', 'celeba.zip')","metadata":{"cellId":"u5keqxbh78nr4wwlg0yf","trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"%enable_full_walk","metadata":{"cellId":"kh1tkdfyde40ds3ku4f7g","trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# import zipfile\n# with zipfile.ZipFile('celeba.zip', 'r') as zip_ref:\n#     zip_ref.extractall('.')","metadata":{"cellId":"1m1o3awxea7iqkxumulns","trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"В этом домашнем задании мы будем работать с Celeba. Celeba - это уже известный вам датасет состоящий из фотографий селеб в их привычной местности:","metadata":{"cellId":"rnwzhzuwrolrjcp4d6z8br"}},{"cell_type":"code","source":"from pytorch_lightning import Trainer, LightningDataModule\nfrom pytorch_lightning.loggers import WandbLogger\nimport model as m","metadata":{"cellId":"c3k2apr7z8ou8e8wprdyc","trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"image_size=(128, 128)\ntransforms = torchvision.transforms.Compose([\n    torchvision.transforms.Resize(image_size),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n])","metadata":{"cellId":"ts903ombkolatbue4t7r89","trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class CelebaDataModule(LightningDataModule):\n\n    def __init__(self, data_dir: str = \"celeba\", batch_size: int = 64, num_workers: int = 32):\n        super().__init__()\n        self.data_dir = data_dir\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n\n    def setup(self, stage = None):\n        self.celeba = torchvision.datasets.CelebA('celeba', target_type='attr', transform=transforms, target_transform=lambda l: l.float(), download=False)\n        self.train_dataset, self.val_dataset = torch.utils.data.random_split(self.celeba, lengths=[len(self.celeba) - 500, 500])\n\n    def train_dataloader(self):\n        return torch.utils.data.DataLoader(self.train_dataset, self.batch_size, shuffle=True, num_workers=self.num_workers)\n\n    def val_dataloader(self):\n        return torch.utils.data.DataLoader(self.val_dataset, self.batch_size, shuffle=False, num_workers=self.num_workers)\n\n\nceleba = CelebaDataModule()","metadata":{"cellId":"6307bmruh8id7k984ll5ue","trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"attrs = '5_o_Clock_Shadow Arched_Eyebrows Attractive Bags_Under_Eyes Bald Bangs Big_Lips Big_Nose Black_Hair Blond_Hair Blurry Brown_Hair Bushy_Eyebrows Chubby Double_Chin Eyeglasses Goatee Gray_Hair Heavy_Makeup High_Cheekbones Male Mouth_Slightly_Open Mustache Narrow_Eyes No_Beard Oval_Face Pale_Skin Pointy_Nose Receding_Hairline Rosy_Cheeks Sideburns Smiling Straight_Hair Wavy_Hair Wearing_Earrings Wearing_Hat Wearing_Lipstick Wearing_Necklace Wearing_Necktie Young'\nindex2attr = {i:j for i, j in enumerate(attrs)}","metadata":{"cellId":"7jzfc4xl7itwyv1lrh2fde","trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from importlib import reload","metadata":{"cellId":"t358uelc8ca3cpqo94vayc","trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"reload(m)","metadata":{"cellId":"5oo7kfjugz34d5gjko98v2","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<module 'model' from '/home/jupyter/work/resources/DeepGenerativeModels/homework/2-GAN/model.py'>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"images, labels = [], []\nfor i, (image, label) in zip(range(5), torchvision.datasets.CelebA('celeba', target_type='attr', transform=transforms, target_transform=lambda l: l.float(), download=False)):\n    images.append(image.unsqueeze(0))\n    labels.append(label.unsqueeze(0))\nimages, labels = torch.cat(images, 0), torch.cat(labels, 0)","metadata":{"cellId":"siw5p0m8e472javql785","trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"#!XL\ntrainer = Trainer(logger=WandbLogger(project='GAN-homework_2-GAN', save_dir=None), log_every_n_steps=20, gpus=-1, accelerator='dp')\nmodel__ = m.VanillaStarGAN(images, labels, index2attr)","metadata":{"cellId":"xkrg0ej3fqrq4y9g9aipkm","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"GPU available: True, used: True\nTPU available: None, using: 0 TPU cores\n"}],"execution_count":13},{"cell_type":"code","source":"#!XL\n__spec__ = None\ntrainer.fit(model__, datamodule=celeba)","metadata":{"cellId":"gx03l1jpfw4fzqs8mdenej","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"/home/jupyter/.local/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: you passed in a val_dataloader but have no validation_step. Skipping validation loop\n  warnings.warn(*args, **kwargs)\nFailed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mpenchekrak\u001B[0m (use `wandb login --relogin` to force relogin)\n"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                Tracking run with wandb version 0.10.22<br/>\n                Syncing run <strong style=\"color:#cdcd00\">scarlet-mountain-22</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/penchekrak/GAN-homework_2-GAN\" target=\"_blank\">https://wandb.ai/penchekrak/GAN-homework_2-GAN</a><br/>\n                Run page: <a href=\"https://wandb.ai/penchekrak/GAN-homework_2-GAN/runs/9n0j55sq\" target=\"_blank\">https://wandb.ai/penchekrak/GAN-homework_2-GAN/runs/9n0j55sq</a><br/>\n                Run data is saved locally in <code>/home/jupyter/work/resources/DeepGenerativeModels/homework/2-GAN/wandb/run-20210313_221729-9n0j55sq</code><br/><br/>\n            "},"metadata":{}},{"output_type":"stream","name":"stderr","text":"\n  | Name          | Type          | Params\n------------------------------------------------\n0 | discriminator | Discriminator | 45.0 M\n1 | generator     | Generator     | 8.5 M \n------------------------------------------------\n53.6 M    Trainable params\n0         Non-trainable params\n53.6 M    Total params\n214.356   Total estimated model params size (MB)\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"807f821eec6d436da3716ef6345fc5e2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"error","ename":"AttributeError","evalue":"'NoneType' object has no attribute 'val_dataloader'","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)","\u001B[0;32m<ipython-input-3-8dd08955af30>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0m__spec__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel__\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdatamodule\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mceleba\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;31m#\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    513\u001B[0m         \u001B[0;31m# dispath `start_training` or `start_testing` or `start_predicting`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 514\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    515\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    516\u001B[0m         \u001B[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001B[0m in \u001B[0;36mdispatch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    552\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    553\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 554\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maccelerator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    555\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    556\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mtrain_or_test_or_predict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001B[0m in \u001B[0;36mstart_training\u001B[0;34m(self, trainer)\u001B[0m\n\u001B[1;32m     72\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     73\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstart_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 74\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_type_plugin\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     75\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     76\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstart_testing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001B[0m in \u001B[0;36mstart_training\u001B[0;34m(self, trainer)\u001B[0m\n\u001B[1;32m    109\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstart_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m'Trainer'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m         \u001B[0;31m# double dispatch to initiate the training loop\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 111\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_results\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_train\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    112\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstart_testing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m'Trainer'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001B[0m in \u001B[0;36mrun_train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    643\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"run_training_epoch\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    644\u001B[0m                     \u001B[0;31m# run train epoch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 645\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_loop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_training_epoch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    646\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    647\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_steps\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_steps\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mglobal_step\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001B[0m in \u001B[0;36mrun_training_epoch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    556\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    557\u001B[0m         \u001B[0;31m# epoch end hook\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 558\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_on_epoch_end_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch_output\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    559\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    560\u001B[0m         \u001B[0;31m# log epoch metrics\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001B[0m in \u001B[0;36mrun_on_epoch_end_hook\u001B[0;34m(self, epoch_output)\u001B[0m\n\u001B[1;32m    804\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    805\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'on_train_epoch_end'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepoch_output\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 806\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'on_epoch_end'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    807\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    808\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mincrement_accumulated_grad_global_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001B[0m in \u001B[0;36mcall_hook\u001B[0;34m(self, hook_name, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1107\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mis_overridden\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhook_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel_ref\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1108\u001B[0m                 \u001B[0mhook_fx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_ref\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1109\u001B[0;31m                 \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhook_fx\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1110\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1111\u001B[0m             \u001B[0;31m# if the PL module doesn't have the hook then call the accelerator\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/work/resources/DeepGenerativeModels/homework/2-GAN/model.py\u001B[0m in \u001B[0;36mon_epoch_end\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    217\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mon_epoch_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 218\u001B[0;31m         \u001B[0mfid_score\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcalculate_fid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgenerator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdatamodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mval_dataloader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    219\u001B[0m         \u001B[0mdiscriminator_accuracy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcalculate_multilabel_accuracy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdiscriminator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdatamodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mval_dataloader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    220\u001B[0m         \u001B[0mcontrol_images\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgenerate_images\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontrol_images\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdesired_labels\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# , self.original_labels\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'val_dataloader'"]}],"execution_count":14},{"cell_type":"markdown","source":"В этой домашней работе вам предлагается повторить результаты статьи StarGAN (https://arxiv.org/abs/1711.09020). \n\nОсновная часть домашнего задания - чтение статьи и улучшение результатов, поэтому обязательно прочитайте не только StarGAN, но и другие Image-to-Image GAN подходы того времени (17-18 год) \n","metadata":{"cellId":"5lsn6jvhlfme4ivmjgctmv"}},{"cell_type":"markdown","source":"## Задача 1 (0.4 балла):\n\nПовторить результаты StarGAN используя только CelebA\n\nчто это значит: в статье предлагается способ использовать несколько датасетов и выучивание аттрибутов уникальных для какого-то одного датасета. Мы не просим вас это делать, вам достаточно просто обучить StarGAN на CelebA","metadata":{"cellId":"6b8f3tu6rp9n9fz3pdds"}},{"cell_type":"code","source":"from model import StarGAN\nfrom utils import permute_labels\n\nmodel = StarGAN()","metadata":{"cellId":"dnuj95b3ts7ys0zta1zkba"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.train()\nfor image, label in tqdm(celeba_dataloader, leave=False, desc=f\"trainloop: {epoch}\"):\n    # YOUR CODE\n\nmodel.eval()\nfor ind, (image, label) in enumerate(celeba_val_dataloader): # batch = 1\n    if ind >= 10: break\n\n    # пример сравнения качества на глаз:\n    new_label = permute_labels(label)\n    plt.figure(figsize=(20, 10))\n    plt.subplot(1, 2, 1)\n    plt.imshow((image[0].permute(1, 2, 0) + 1) / 2)\n    plt.subplot(1, 2, 2)\n    fake_image = model.generate(image.to(device), new_label.to(device)).detach().cpu()[0]\n    plt.imshow((fake_image.permute(1, 2, 0) + 1) / 2)\n    plt.show()\n","metadata":{"cellId":"m7z2mc2sqe87tgrwpnpqs"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Важно 4: \n\nЕсли вы учите на колабе или на наших машинках, вероятнее всего что обучение будет очень долгим на картинках 256х256. Никто не мешает уменьшить разрешение, главное чтобы было видно что трансформации выучились\n\nЕще, кажется что не все аттрибуты селебы являются очень важными или достаточно представленными в датасете. Не запрещается убирать бесполезные аттрибуты (только обоснуйте почему так сделали в отчете)\n\nНе забывайте про аугментации\n\n## Важно 5: \n\nДа, мы знаем что в на гитхабе лежить готовый код на путорче для этой статьи. Проблема в том что он написал на torch 0.4, поэтому, если мы увидим что вы используете __старый__ код со старыми модулями, то мы:\n\n1. Будем неодобрительно смотреть\n2. За наглое списывание будем снимать баллы\n","metadata":{"cellId":"qge7o31vyaj3na9i6rqkmy"}},{"cell_type":"markdown","source":"## Задача 2 (0.2 балла): \n\nМерить качество на глаз - плохая идея. Подключите подсчет FID для каждой N эпохи, чтобы вы могли следить за прогрессом модели.\n\nСранение моделей между собой тоже возможно только по FID, поэтому трекайте его когда будете делать другие эксперименты","metadata":{"cellId":"0fvt5znbuezax5n30l3x009"}},{"cell_type":"markdown","source":"## Задача 3 (0.4 балла):\n\nЕсли вы будете дословно повторять архитектуру авторов статьи, вы сразу же увидите что обучение станет дико долгим и не очень стабильным. Возможно у вас получится предложить несколько улучшений, которые приведут к хорошему FID, к визуально лучшим результатам или к более стабильному обучению.\n\nВ этой задаче хочется чтобы вы попробовали улучшить результаты статьи используя либо то что уже знаете, либо что-то из релевантных статей по Im2Im современности","metadata":{"cellId":"nklvmt721tpsrzfx6717pi"}},{"cell_type":"markdown","source":"## Важно 6: \n\nКогда вы будете показывать визуальные трансформации которые делает ваш StarGAN, хорошей идеей будет сразу же зафиксировать набор картинок (очевидно из валидации) и набор трансформаций на которых вы будете показывать результаты. Например: 10 картинок разных людей на которых вы покажете Male-Female, Beard-noBeard, Old-Young трансформации","metadata":{"cellId":"4zitx661e5qb9h1tl9k3b4"}},{"cell_type":"markdown","source":"## Важно 7 (0.15 балла): \n\nВыдам дополнительные баллы если у вас получится визуально красивая перекраска волос в разные цвета","metadata":{"cellId":"ncz2ahkji0jwvahurjvw6"}}]}